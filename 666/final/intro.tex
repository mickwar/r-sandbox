\section{Introduction} % and motivating example

A decision tree is a convenient tool for making decisions or predictions based on simple divisions in the predictor space. 

Tree-based methods involve dividing the predictor variables, or feature space, $X_1,\ldots,X_p$ into $J$ distinct and non-overlapping regions $R_1,\ldots,R_J$. Predictions for region $j$ are typically based on the mean or mode of the responses in $R_j$. This allows for easily interpretable results

Let $\m{y}_i$ denote the $q$-vector of responses for observation $i$ and $\m{x}_i$ as the $p$-vector of corresponding features.

Random forests are used for both regression and classification.

