\section{Example: movie preferences}

The methods in section 2 are applied to a movie preference data set. A willing subject was asked two questions per movie: (1) Did you like the movie? and (2) Did you think it was well-executed? The list of movies came from the subject's personal history of movies watched. A ``yes'' response to question one indicates the participant generally liked the movie. A ``yes'' to the second question means the participant felt that the movie was well-made (regardless of whether the movie was liked) in terms of acting, cinematography, soundtrack, and other general qualities of a movie. There are thus four possible categories:
\begin{enumerate}
\item Liked, and well-executed
\item Liked, but not well-executed
\item Disliked, but well-executed
\item Disliked, and not well-executed
\end{enumerate}
As is expected, there are few movies (only two in this dataset) that the subject liked but did not think were well-made. We remove those movies from the data set and consider only the movies in classes 1, 3, and 4.

Movie attributes are Rotten Tomato scores (\texttt{rot\_crit}), Kids in Mind ratings (violence \texttt{kids\_V}, sexual \texttt{kids\_S}, and profanity \texttt{kids\_P}), year of release (\texttt{year}), MPAA rating (\texttt{G}, \texttt{PG}, and \texttt{PG13}), and an indicator for whether the movie was animated or not (\texttt{live\_action}). Some movies do not have a Rotten Tomatoes score and others do not have Kids in Mind ratings; these movies were also removed from the data set. We are left with $n=71$ observations.

We randomly set aside 40 observations for a training set and the remaining 31 as a test set. A large number of trees are grown on bootstrap samples of the training set where at each node a random sample of $m=\sqrt{9}=3$ predictors are chosen to split the node.

The \texttt{randomForest} package in R is used to perform the analysis. We use the \texttt{randomForest()} function's default settings. In classification, the function will grow trees to maximal size so every observation is in it's own terminal node. Classification error rates are given in figure \ref{error}. A property of random forests is that error rates (and mean squared for regression) will converge to the true error rate for the training sample as the number of trees grows. Often, 500 trees will suffice.

\begin{figure}
\begin{center}
\includegraphics[scale=0.4]{figs/forest_error.pdf}
\caption{Classification error rates for each group.}
\label{error}
\end{center}
\end{figure}

The variables that contributed the most in growing the trees are shown in figure \ref{import} (left). The Kids in Mind sexual content rating (\texttt{kids\_S}) contributed the most to class separation, followed by Rotten Tomatoes critic ratings (\texttt{rot\_crit}) and year of release (\texttt{year}). With there being so many trees, it is difficult to interpret \emph{how} the variables are separating the classes. We look at one tree (figure \ref{import}, right) that is grown using the full data set to give us an idea of how some of the more important variables are causing the splits. 

\begin{figure}
\begin{center}
\includegraphics[scale=0.35]{figs/importance2.pdf}
\caption{Variables ordered by importance (from top to bottom) as measured by the mean decrease in the Gini index.}
\label{import}
\end{center}
\end{figure}

We see that, generally, movies with a lower sex content are more likely to be liked (class 1) by the subject. The subject also generally agrees with the critics at Rotten Tomatoes, with a few exceptions. The MPAA ratings have little influence on whether the subject will like the movie. A similar statement could be said for the violence content and whether the movie is animated (a 0 for \texttt{live\_action}).

\begin{table}
\begin{center}
\begin{tabular}{lr|rrr|r}
     & \multicolumn{1}{l}{}   & \multicolumn{3}{c}{Predicted} \\
     &    &  1 & 3 & 4 & Error \\ \cline{2-6}
     & 1  & \textbf{15} & 0 & 2 & 0.11 \\
True & 3  &  2 & \textbf{2} & 3 & 0.71 \\
     & 4  &  5 & 0 & \textbf{2} & 0.71 \\
\end{tabular}
\caption{Confusion matrix for the test set. We see that movies in class 1 are well explained by the model, but classes 3 and 4 are harder to classify.}
\label{confuse}
\end{center}
\end{table}

The confusion matrix shown in table \ref{confuse} shows the predictions versus the tree classes for the test set, the 31 observations held out. Classes 3 and 4 are more difficult to classify, perhaps because of the small amount of observations with those classes (people do not usually watch movies they think they will not like). Those classes may also have high error rates because of a lack of variables describing the movie attributes. Notice the similarity in error rates shown in the confusion matrix and in figure \ref{error}.
